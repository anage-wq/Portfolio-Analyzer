# -*- coding: utf-8 -*-
"""Untitled58.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dt5wsEu-Gxprz6i7SSGViSdxvYDJOqMz
"""

import pandas as pd
import yfinance as yf

from datetime import datetime, timedelta, date
from scipy.optimize import newton

tradebook = pd.read_csv("/content/TradeBook.csv")  # or any pandas DataFrame

securities = ['NIFTYBEES', 'BANKBEES', 'MID150BEES', 'HDFCSML250']
xirr_vals=[]
wv_3m=[]
wv_6m=[]
wv_1y=[]
wdd_3m=[]
wdd_6m=[]
wdd_1y=[]

# -*- coding: utf-8 -*-
"""portfolio_volatility&drawdown_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k1BSBM7YKL7L-lLnFBSzd4KbDzmWV_eK
"""

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

def calculate_volatility(prices):
    returns = prices.pct_change().dropna()
    volatility = returns.std() * np.sqrt(252)
    return volatility * 100

def calculate_max_drawdown(prices):
    cumulative = (1 + prices.pct_change()).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    max_drawdown = drawdown.min()
    return max_drawdown * 100

def get_stock_data(symbol, period_days):
    try:
        ticker_symbol = f"{symbol}.NS"
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days + 30)
        ticker = yf.Ticker(ticker_symbol)
        hist = ticker.history(start=start_date, end=end_date)
        if hist.empty or len(hist) < 10:
            return None
        hist = hist.tail(period_days) if len(hist) > period_days else hist
        return hist
    except Exception as e:
        print(f"Error fetching {symbol}: {str(e)}")
        return None

def analyze_individual_stock(symbol, period_days):
    hist = get_stock_data(symbol, period_days)
    if hist is None or hist.empty:
        return None, None
    volatility = calculate_volatility(hist['Close'])
    max_dd = calculate_max_drawdown(hist['Close'])
    return volatility, max_dd

def calculate_portfolio_metrics(portfolio_data, period_days):
    stock_prices = {}
    stock_returns = {}
    stock_weights = {}
    total_value = 0
    valid_stocks = []
    # Use "Quantity" column for consistency
    for idx, row in portfolio_data.iterrows():
        symbol = row['Symbol']
        # Now 'Quantity' is guaranteed to exist due to check in analyze_portfolio
        quantity = row['Quantity']
        hist = get_stock_data(symbol, period_days)
        if hist is not None and not hist.empty:
            current_price = hist['Close'].iloc[-1]
            stock_value = current_price * quantity
            total_value += stock_value
            stock_prices[symbol] = hist['Close']
            stock_returns[symbol] = hist['Close'].pct_change().dropna()
            valid_stocks.append({
                'Symbol': symbol,
                'Quantity': quantity,
                'CurrentPrice': current_price,
                'Value': stock_value
            })

    if total_value == 0 or not valid_stocks:
        return None, None, None, 0

    # Calculate weights
    for stock in valid_stocks:
        stock['Weight'] = stock['Value'] / total_value
        stock_weights[stock['Symbol']] = stock['Weight']

    returns_df = pd.DataFrame(stock_returns)
    returns_df = returns_df.dropna()
    if returns_df.empty:
        return None, None, None, total_value

    weights_series = pd.Series(stock_weights)
    portfolio_returns = (returns_df * weights_series).sum(axis=1)
    portfolio_volatility = portfolio_returns.std() * np.sqrt(252) * 100
    portfolio_cumulative = (1 + portfolio_returns).cumprod()
    running_max = portfolio_cumulative.expanding().max()
    drawdown = (portfolio_cumulative - running_max) / running_max
    portfolio_max_dd = drawdown.min() * 100

    return portfolio_volatility, portfolio_max_dd, valid_stocks, total_value

def analyze_portfolio(portfolio, periods):
    # Check if 'Quantity' column exists. If not, create a placeholder and inform the user.
    if 'Quantity' not in portfolio.columns:
        print("Warning: 'Quantity' column not found in the portfolio data. Assuming a quantity of 1 for each stock for now.")
        print("Please ensure your input CSV has a 'Quantity' column or update the code to use the correct column name for stock quantity.")
        portfolio['Quantity'] = 1 # Placeholder

    results = portfolio[['Symbol', 'Quantity']].copy()
    portfolio_metrics = {}
    # Initialize scores if needed
    wv = {}
    wdd = {}

    for period_name, days in periods.items():
        volatility_col = f'Volatility_{period_name}_%'
        drawdown_col = f'Max_Drawdown_{period_name}_%'
        results[volatility_col] = None
        results[drawdown_col] = None
        for idx, row in portfolio.iterrows():
            symbol = row['Symbol']
            vol, dd = analyze_individual_stock(symbol, days)
            if vol is not None and dd is not None:
                results.at[idx, volatility_col] = round(vol, 2)
                results.at[idx, drawdown_col] = round(dd, 2)

        # Pass the modified portfolio (with placeholder 'Quantity' if needed)
        p_vol, p_dd, stock_info, total_val = calculate_portfolio_metrics(portfolio, days)
        wv[period_name] = p_vol
        wdd[period_name] = p_dd
        if p_vol is not None:
            portfolio_metrics[period_name] = {
                'volatility': p_vol,
                'max_drawdown': p_dd,
                'total_value': total_val,
                'stock_info': stock_info
            }
    return results, portfolio_metrics, wv, wdd

def save_results(results, portfolio_metrics, periods):
    output_file = 'portfolio_analysis_individual_stocks.csv'
    results.to_csv(output_file, index=False)
    print(f"Individual stock results saved to: {output_file}")

    portfolio_summary = []
    for period_name, metrics in portfolio_metrics.items():
        portfolio_summary.append({
            'Period': period_name.replace('_', ' ').title(),
            'Portfolio_Volatility_%': round(metrics['volatility'], 2),
            'Portfolio_Max_Drawdown_%': round(metrics['max_drawdown'], 2),
            'Total_Portfolio_Value_â‚¹': round(metrics['total_value'], 2)
        })
    portfolio_df = pd.DataFrame(portfolio_summary)
    portfolio_output = 'portfolio_analysis_weighted_portfolio.csv'
    portfolio_df.to_csv(portfolio_output, index=False)
    print(f"Portfolio-level results saved to: {portfolio_output}")
    return portfolio_df

def main():
    # Use preprocessed/combined portfolio DataFrame
    portfolio = pd.read_csv('/content/Final_portfolio_with_price (1).csv')
    print("Columns in portfolio DataFrame:", portfolio.columns.tolist())

    periods = {
        '3_months': 90,
        '6_months': 180,
        '1_year': 365
    }
    results, portfolio_metrics, wv, wdd = analyze_portfolio(portfolio, periods)
    portfolio_df = save_results(results, portfolio_metrics, periods)

    print("\nSUMMARY - INDIVIDUAL STOCKS")
    for period_name in periods.keys():
        vol_col = f'Volatility_{period_name}_%'
        dd_col = f'Max_Drawdown_{period_name}_%'
        print(f"\n{period_name.replace('_', ' ').title()}:")
        print(f"  Average Volatility: {results[vol_col].mean():.2f}%")


        print(f"  Average Max Drawdown: {results[dd_col].mean():.2f}%")
        max_vol_idx = results[vol_col].idxmax()
        min_dd_idx = results[dd_col].idxmin()
        if pd.notna(max_vol_idx):
            print(f"  Highest Volatility: {results.loc[max_vol_idx, vol_col]:.2f}% ({results.loc[max_vol_idx, 'Symbol']})")
        if pd.notna(min_dd_idx):
            print(f"  Worst Drawdown: {results.loc[min_dd_idx, dd_col]:.2f}% ({results.loc[min_dd_idx, 'Symbol']})")

    print("\nSUMMARY - WEIGHTED PORTFOLIO")
    print(portfolio_df.to_string(index=False))

    # Show holdings by weight from most recent period's metrics
    if portfolio_metrics:
        last_period = list(portfolio_metrics.keys())[-1]
        stock_info = portfolio_metrics[last_period]['stock_info']
        print("\nHOLDINGS BY WEIGHT")
        stock_info_df = pd.DataFrame(stock_info).sort_values('Weight', ascending=False)
        stock_info_df['Weight_%'] = (stock_info_df['Weight'] * 100).round(2)
        print(stock_info_df[['Symbol', 'Quantity', 'CurrentPrice', 'Value', 'Weight_%']].to_string(index=False))
    return results, portfolio_df, wv, wdd

if __name__ == "__main__":
    results, portfolio_summary, wv_main, wdd_main = main()

# -*- coding: utf-8 -*-
"""Portfolio_xirr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRRX8VSpYPnDtU7OBiOJRkO-JSw0YxnJ
"""

import pandas as pd
import yfinance as yf
from datetime import date
from scipy.optimize import newton
import json
import warnings

warnings.filterwarnings('ignore', category=FutureWarning)  # Suppress pandas concat warnings


class DataPreprocessor:
    """Single Responsibility: Preprocess raw trade data."""
    def __init__(self, dataframe):
        self.df = dataframe

    def preprocess(self):
        self.df = self.df.drop(['Segment', 'Series', 'Auction', 'Trade ID', 'Order ID', 'Order Execution Time'], axis=1, errors='ignore')
        self.df['Trade Type'] = self.df['Trade Type'].str.lower()
        self.df['Trade Date'] = pd.to_datetime(self.df['Trade Date'], dayfirst=True, errors='coerce', format='mixed').dt.tz_localize(None)
        self.df['Quantity'] = pd.to_numeric(self.df['Quantity'].astype(str).str.replace(',', '', regex=False), errors='coerce')
        self.df['Price'] = pd.to_numeric(self.df['Price'].astype(str).str.replace(',', '', regex=False), errors='coerce')
        return self.df


class SymbolResolver:
    """Single Responsibility: Resolve symbol ambiguity."""
    def __init__(self, dataframe):
        self.df = dataframe.copy()

    def is_delisted(self, symbol, suffix):
        try:
            ticker = yf.Ticker(symbol + suffix)
            hist = ticker.history(period='1d')
            return hist.empty
        except Exception:
            return True

    def resolve(self):
        df_unique = self.df[['ISIN', 'Symbol', 'Exchange']].drop_duplicates(subset=['Symbol'])
        isin_symbol_counts = df_unique.groupby('ISIN')['Symbol'].nunique()
        ambiguous_isins = isin_symbol_counts[isin_symbol_counts > 1].index
        ambiguous_symbols = df_unique[df_unique['ISIN'].isin(ambiguous_isins)]

        for _, group in ambiguous_symbols.groupby('ISIN'):
            symbols = list(group['Symbol'])
            exchanges = list(group['Exchange'])
            if len(symbols) < 2:
                continue
            s1, s2 = symbols[0], symbols[1]
            e1, e2 = exchanges[0], exchanges[1]
            suf1 = '.NS' if e1 == 'NSE' else '.BO' if e1 == 'BSE' else ''
            if self.is_delisted(s1, suf1):
                to_replace, replacement = s1, s2
            else:
                to_replace, replacement = s2, s1
            self.df.loc[self.df['Symbol'] == to_replace, 'Symbol'] = replacement
        return self.df


class StockSplitAdjuster:
    """Single Responsibility: Adjust trades for stock splits."""
    def __init__(self, df, split_json_path):
        self.df = df.copy()
        self.split_json_path = split_json_path

    def load_external_splits(self):
        try:
            with open(self.split_json_path, 'r') as f:
                raw = json.load(f)
        except Exception as e:
            print(f"Warning: Could not load split JSON: {e}")
            return pd.DataFrame(columns=['Symbol', 'Split Date', 'Split Ratio'])

        records = []
        for item in raw.get('Company_Ticker', []):
            if isinstance(item, dict):
                records.append({
                    'Symbol': item.get('symbol'),
                    'Split Date': pd.to_datetime(item.get('date'), dayfirst=True, errors='coerce'),
                    'Split Ratio': pd.to_numeric(item.get('stock_split'), errors='coerce')
                })
        return pd.DataFrame(records)

    def fetch_yfinance_splits(self):
        unique_syms = self.df[['Symbol', 'Exchange']].drop_duplicates()
        splits_list = []
        for _, row in unique_syms.iterrows():
            sym, exch = row['Symbol'], row['Exchange']
            ticker = f"{sym}.NS" if exch == 'NSE' else f"{sym}.BO" if exch == 'BSE' else sym
            try:
                splits = yf.Ticker(ticker).splits
                if splits.empty:
                    continue
                temp_df = splits.reset_index()
                temp_df.columns = ['Split Date', 'Split Ratio']
                temp_df['Symbol'] = sym
                temp_df['Exchange'] = exch
                splits_list.append(temp_df)
            except Exception as e:
                print(f"Warning: Could not fetch splits for {ticker}: {e}")

        if splits_list:
            df_splits = pd.concat(splits_list).reset_index(drop=True)
            df_splits['Split Date'] = pd.to_datetime(df_splits['Split Date']).dt.tz_localize(None)
            return df_splits
        else:
            return pd.DataFrame(columns=['Split Date', 'Split Ratio', 'Symbol', 'Exchange'])

    def adjust(self):
        external_splits = self.load_external_splits()
        yfinance_splits = self.fetch_yfinance_splits()

        external_splits['Split Date'] = pd.to_datetime(external_splits['Split Date'], errors='coerce').dt.tz_localize(None)
        yfinance_splits['Split Date'] = pd.to_datetime(yfinance_splits['Split Date'], errors='coerce').dt.tz_localize(None)

        combined_splits = pd.concat([yfinance_splits, external_splits], ignore_index=True, join='inner')
        combined_splits.drop_duplicates(subset=['Symbol', 'Split Date', 'Split Ratio'], inplace=True)
        combined_splits['Split Date'] = combined_splits['Split Date'].dt.normalize()

        self.df['Trade Date'] = pd.to_datetime(self.df['Trade Date'], errors='coerce').dt.tz_localize(None).dt.normalize()

        combined_splits = combined_splits.sort_values('Split Date')

        for _, split in combined_splits.iterrows():
            sym, split_date, ratio = split['Symbol'], split['Split Date'], split['Split Ratio']
            if pd.isna(sym) or pd.isna(split_date) or pd.isna(ratio):
                continue
            mask = (self.df['Symbol'] == sym) & (self.df['Trade Date'] < split_date)
            self.df.loc[mask, 'Quantity'] *= ratio
            self.df.loc[mask, 'Price'] /= ratio

        return self.df


class CashFlowCalculator:
    """Single Responsibility: Calculate cash flows for trades."""
    def __init__(self, df):
        self.df = df.copy()

    def calculate(self):
        self.df['Cash Flow'] = self.df.apply(
            lambda r: r['Quantity'] * r['Price'] if r['Trade Type'] == 'sell' else -r['Quantity'] * r['Price'], axis=1)
        return self.df


class XIRRCalculator:
    """Single Responsibility: Calculate XIRR for portfolio including current values."""
    def __init__(self, tradebook_df, external_price_path=None):
        self.df = tradebook_df
        self.external_price_path = external_price_path

    @staticmethod
    def _npv(rate, dates, cashflows):
        dates = [pd.to_datetime(d).tz_localize(None) if pd.to_datetime(d).tzinfo else pd.to_datetime(d) for d in dates]
        dates.sort()
        time_in_years = [(d - dates[0]).days / 365 for d in dates]
        return sum(cf / (1 + rate) ** ti for cf, ti in zip(cashflows, time_in_years))

    @staticmethod
    def _xirr(dates, cashflows):
        if not any(cf > 0 for cf in cashflows) or not any(cf < 0 for cf in cashflows):
            return None
        try:
            return newton(lambda r: XIRRCalculator._npv(r, dates, cashflows), x0=0.1, tol=1e-6, maxiter=100)
        except (RuntimeError, ValueError):
            return None

    def get_current_price(self, symbol, exchange):
        ticker_symbol = f'{symbol}.NS' if exchange == 'NSE' else f'{symbol}.BO' if exchange == 'BSE' else symbol
        try:
            ticker = yf.Ticker(ticker_symbol)
            info = ticker.info
            price = info.get('regularMarketPrice') or info.get('currentPrice') or info.get('previousClose')
            return price
        except Exception:
            return None

    def load_external_prices(self):
        if not self.external_price_path:
            return {}
        try:
            with open(self.external_price_path, 'r') as f:
                return json.load(f)
        except Exception:
            return {}

    def calculate(self):
        current_prices = {}
        external_prices = self.load_external_prices()

        for symbol, exch in self.df[['Symbol', 'Exchange']].drop_duplicates().values:
            price = self.get_current_price(symbol, exch)
            if price is None:
                price = external_prices.get(symbol)
            if price is not None:
                current_prices[symbol] = price
        current_prices.update(external_prices)

        self.df['signed_quantity'] = self.df.apply(lambda r: r['Quantity'] if r['Trade Type'] == 'buy' else -r['Quantity'], axis=1)
        holdings = self.df.groupby('Symbol')['signed_quantity'].sum()

        current_value = 0
        for sym, qty in holdings.items():
            if qty > 0:
                price = current_prices.get(sym)
                if price:
                    current_value += qty * price

        df_clean = self.df.dropna(subset=['Trade Date', 'Cash Flow'])
        dates = df_clean['Trade Date'].tolist()
        cashflows = df_clean['Cash Flow'].tolist()

        if current_value > 0 and dates:
            dates.append(pd.to_datetime(date.today()))
            cashflows.append(current_value)

        if not dates or not cashflows or len(dates) != len(cashflows):
            return None

        sorted_events = sorted(zip(dates, cashflows))
        sorted_dates, sorted_cashflows = zip(*sorted_events)

        result = self._xirr(list(sorted_dates), list(sorted_cashflows))
        return result * 100 if result is not None else None


# Usage example:
if __name__ == '__main__':
    try:
        ds = pd.read_csv('/content/TradeBook.csv')
    except Exception as e:
        print(f"Error loading CSV: {e}")
        ds = pd.DataFrame()

    if not ds.empty:
        preprocessor = DataPreprocessor(ds)
        ds1 = preprocessor.preprocess()

        resolver = SymbolResolver(ds1)
        ds2 = resolver.resolve()

        split_adjuster = StockSplitAdjuster(ds2, '/content/Stock_split_external.json')
        ds3 = split_adjuster.adjust()

        cash_flow_calc = CashFlowCalculator(ds3)
        ds4 = cash_flow_calc.calculate()

        xirr_calc = XIRRCalculator(ds4, '/content/external_stoc_current_price.json')
        portfolio_xirr = xirr_calc.calculate()
        xirr_vals.append(portfolio_xirr)

        if portfolio_xirr is not None:
            print(f"Portfolio XIRR: {portfolio_xirr:.2f}%")
        else:
            print("XIRR calculation failed.")
    else:
        print("TradeBook data unavailable or empty. Aborting.")

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class StockDataFetcher:
    """Handles all stock data fetching logic"""
    def __init__(self, exchange_suffix='.NS', buffer_days=30):
        self.exchange_suffix = exchange_suffix
        self.buffer_days = buffer_days

    def fetch(self, symbol, period_days):
        """Returns historical price DataFrame for the given symbol"""
        ticker_symbol = f"{symbol}{self.exchange_suffix}"
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days + self.buffer_days)
        try:
            ticker = yf.Ticker(ticker_symbol)
            hist = ticker.history(start=start_date, end=end_date)
            if hist.empty or len(hist) < 10:
                return None
            return hist.tail(period_days) if len(hist) > period_days else hist
        except Exception as e:
            print(f"Error fetching {symbol}: {str(e)}")
            return None

class VolatilityCalculator:
    """Calculates volatility statistics for a price series"""
    @staticmethod
    def annualized_volatility(price_series):
        returns = price_series.pct_change().dropna()
        return returns.std() * np.sqrt(252) * 100  # Percentage

class DrawdownCalculator:
    """Calculates drawdown for a price series"""
    @staticmethod
    def max_drawdown(price_series):
        cumulative = (1 + price_series.pct_change()).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        return drawdown.min() * 100  # Percentage

class PortfolioAnalyzer:
    """Analyzes a portfolio DataFrame and runs analytics functions"""
    def __init__(self, stock_fetcher):
        self.stock_fetcher = stock_fetcher

    def analyze_individual_stock(self, symbol, period_days):
        hist = self.stock_fetcher.fetch(symbol, period_days)
        if hist is None or hist.empty:
            return None, None
        vol = VolatilityCalculator.annualized_volatility(hist['Close'])
        dd = DrawdownCalculator.max_drawdown(hist['Close'])
        return vol, dd

    def analyze_portfolio(self, portfolio_df, period_days, quantity_col='CurrentQuantity'):
        stock_weights = {}
        total_value = 0
        valid_stocks = []
        stock_returns = {}
        for idx, row in portfolio_df.iterrows():
            symbol = row['Symbol']
            quantity = row[quantity_col]
            hist = self.stock_fetcher.fetch(symbol, period_days)
            if hist is not None and not hist.empty:
                current_price = hist['Close'].iloc[-1]
                value = current_price * quantity
                total_value += value
                stock_returns[symbol] = hist['Close'].pct_change().dropna()
                valid_stocks.append({
                    'Symbol': symbol,
                    'Quantity': quantity,
                    'CurrentPrice': current_price,
                    'Value': value
                })
        if total_value == 0 or not valid_stocks:
            return None, None, None, 0
        for stock in valid_stocks:
            stock['Weight'] = stock['Value'] / total_value
            stock_weights[stock['Symbol']] = stock['Weight']
        returns_df = pd.DataFrame(stock_returns).dropna()
        if returns_df.empty:
            return None, None, None, total_value
        weights_series = pd.Series(stock_weights)
        portfolio_returns = (returns_df * weights_series).sum(axis=1)
        vol = portfolio_returns.std() * np.sqrt(252) * 100
        cumulative = (1 + portfolio_returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = drawdown.min() * 100
        return vol, max_drawdown, valid_stocks, total_value

def run_analysis(symbols, periods, quantity=1):
    fetcher = StockDataFetcher('.NS', 30)
    analyzer = PortfolioAnalyzer(fetcher)
    # Pre-initialize metrics lists per period
    # Changed to dictionaries to store lists of values per period
    wv_individual = {p: [] for p in periods}
    wdd_individual = {p: [] for p in periods}

    for symbol in symbols:
        portfolio_df = pd.DataFrame({"Symbol": [symbol], "CurrentQuantity": [quantity]})
        for period_name, days in periods.items():
            # Individual Stock
            vol, dd = analyzer.analyze_individual_stock(symbol, days)
            if vol is not None and dd is not None:
                print(f"{symbol} {period_name}: Volatility={vol:.2f}%, MaxDrawdown={dd:.2f}%")
            else:
                print(f"{symbol} {period_name}: No data")
            # Portfolio-level metrics (trivial for single stock, extendable to multi-stock batch)
            p_vol, p_dd, stock_info, total_val = analyzer.analyze_portfolio(portfolio_df, days)
            if p_vol is not None and p_dd is not None:
                print(f"Portfolio {symbol} {period_name}: Weighted Volatility={p_vol:.2f}%, Weighted MaxDrawdown={p_dd:.2f}%")
                # Append to the correct list within the dictionary
                wv_individual[period_name].append(p_vol)
                wdd_individual[period_name].append(p_dd)
    return wv_individual, wdd_individual

if __name__ == "__main__":
    sec = [    "NIFTYBEES",
    "BANKBEES",
    "MID150BEES",
    "HDFCSML250"]
    periods = {'3_months': 90, '6_months': 180, '1_year': 365}
    # Assign directly to global wv and wdd, which are now correctly populated dictionaries
    wv, wdd = run_analysis(sec, periods, quantity=1)

def calculate_xirr_with_current_prices_for_index_funds(tradebook_df, symbl):
    from scipy.optimize import newton
    from datetime import date
    import pandas as pd
    import yfinance as yf
    import pytz

    # --- Internal helper functions for NPV and XIRR ---
    def _npv(rate, dates, cashflows):
        """Calculate Net Present Value."""

        dates = [pd.to_datetime(d).tz_convert(None) if pd.to_datetime(d).tzinfo is not None else pd.to_datetime(d) for d in dates]


        dates.sort()
        if not dates:
            return 0.0

        time_in_years = [(d - dates[0]).days / 365.0 for d in dates]
        return sum(cf / (1 + rate) ** ti for cf, ti in zip(cashflows, time_in_years))


    def _xirr(dates, cashflows):
        """Calculate Extended Internal Rate of Return."""
        # Check if there are both positive and negative cash flows
        if not any(cf > 0 for cf in cashflows) or not any(cf < 0 for cf in cashflows):
            return None
        try:
            # Use Newton-Raphson method to find the root of the NPV equation.
            # Provide a range for the initial guess (x0) to help convergence
            # Adjust bounds as needed based on expected XIRR values
            return newton(lambda r: _npv(r, dates, cashflows), x0=0.1, tol=1e-6, maxiter=100)
        except RuntimeError:
            # Return None if solver does not converge.
            return None
        except ValueError:
            # Return None if input values are not appropriate (e.g., dates not unique)
            return None

    def get_current_stock_price(symbol: str) -> float:
        """
        Fetches the current market price of a stock from Yahoo Finance.

        Args:
            symbol (str): The stock ticker symbol (e.g., 'RELIANCE.NS', 'AAPL').

        Returns:
            float: The current market price, or None if not found.
        """
        try:
            stock = yf.Ticker(symbol)
            # The 'info' attribute contains a dictionary of stock information
            price = stock.info.get('regularMarketPrice')
            return price
        except Exception as e:
            print(f"Error fetching data for {symbol}: {e}")
            return None


    # --- 1. Get current stock price ---
    symbol_with_exchange = f"{symbl}.NS" if '.' not in symbl else symbl
    current_price = get_current_stock_price(symbol_with_exchange)

    if current_price is None:
        print(f"Could not fetch current price for {symbl}. Cannot calculate XIRR.")
        return None

    # --- 2. Calculate the total net quantity of the index fund ---
    # The input tradebook_df already represents the cash flows based on net quantity changes
    # The total net quantity is the sum of the 'Quantity' column in this DataFrame
    total_net_quantity = tradebook_df['Quantity'].sum()


    # --- 3. Calculate the value of current holdings ---
    current_portfolio_value = 0
    if total_net_quantity > 0:
        current_portfolio_value = total_net_quantity * current_price

    # --- 4. Prepare the final cash flow series ---

    # Get the original transaction cash flows and dates from the input DataFrame.
    # Ensure column names are consistent and use .loc for assignment
    df_cleaned = tradebook_df.dropna(subset=['Trade Date', 'Cash_Flow']).copy()
    dates = df_cleaned['Trade Date'].tolist()
    cashflows = df_cleaned['Cash_Flow'].tolist()


    # Add the current portfolio value as the final cash inflow event.
    # This represents the value you would get if you sold everything today.
    if current_portfolio_value > 0 and dates: # Also check if dates is not empty
        # Ensure today's date is timezone-naive
        today_naive = pd.to_datetime(date.today())
        dates.append(today_naive)
        cashflows.append(current_portfolio_value)
    elif current_portfolio_value == 0 and dates:
         # If current holding is zero, add a cashflow of 0 at today's date
         today_naive = pd.to_datetime(date.today())
         dates.append(today_naive)
         cashflows.append(0.0)



    # --- 5. Calculate and return XIRR ---
    # Ensure dates and cashflows are aligned and sorted by date for accurate XIRR
    # Combine dates and cashflows into a list of tuples and sort
    if not dates or not cashflows or len(dates) != len(cashflows):
        return None # Return None if cash flow data is not valid for XIRR calculation

    cashflow_events = sorted(zip(dates, cashflows))
    sorted_dates, sorted_cashflows = zip(*cashflow_events)

    xirr_value = _xirr(list(sorted_dates), list(sorted_cashflows))

    return xirr_value

def common(tradebook,sec):
  import pandas as pd
  from datetime import datetime
  tradebook['Trade Date'] = pd.to_datetime(tradebook['Trade Date'], dayfirst=True, errors='coerce', format='mixed')
  tradebook['Quantity'] = tradebook['Quantity'].astype(str).str.replace(',', '', regex=False)
  tradebook['Quantity'] = pd.to_numeric(tradebook['Quantity'], errors='coerce')
  tradebook['Trade Type'] = tradebook['Trade Type'].str.lower()
  total_quantity_by_date_and_type = tradebook.groupby(['Trade Date', 'Trade Type'])['Quantity'].sum()
  net_quantity_by_date = total_quantity_by_date_and_type.unstack(fill_value=0)
# Calculate net quantity as bought minus sold
  net_quantity_by_date['Net Quantity'] = net_quantity_by_date.get('buy', 0) - net_quantity_by_date.get('sell', 0)
  net_quantity_by_date.reset_index(inplace=True)
  net_quantity_by_date.drop(['buy','sell'],inplace=True,axis=1)
  all_dates=net_quantity_by_date['Trade Date']
  for i in sec:

    import yfinance as yf

    all_dates = pd.to_datetime(all_dates)

    ticker_symbol = i+'.NS'

    start_date = all_dates.min() - pd.Timedelta(days=10)
    end_date = all_dates.max() + pd.Timedelta(days=10)

    data = yf.download(ticker_symbol, start=start_date, end=end_date)

    closing_prices = data['Close'].reindex(all_dates)
    closing_prices.reset_index(inplace=True)
    closing_prices.rename(columns={i+'.NS': 'Price'}, inplace=True)
    closing_prices['Quantity']=net_quantity_by_date['Net Quantity']
    closing_prices['Cash_Flow']=(closing_prices['Quantity']*closing_prices['Price'])*-1
    xirr_vals.append(calculate_xirr_with_current_prices_for_index_funds(closing_prices, i)*100)

tradebook = pd.read_csv("/content/TradeBook.csv")  # or any pandas DataFrame
securities = ['NIFTYBEES', 'BANKBEES', 'MID150BEES', 'HDFCSML250']

common(tradebook,securities)

cols=[
    'Securities',
    'XIRR',
    'Vol_3m',
    'Vol_6m',
    'Vol_1y',
    'MaxDrawdown_3m',
    'MaxDrawdown_6m',
    'MaxDrawdown_1y'
]

final=pd.DataFrame(columns=cols)

comps=['Portfolio','NIFTYBEES', 'BANKBEES', 'MID150BEES', 'HDFCSML250']

comps=['Portfolio','NIFTYBEES', 'BANKBEES', 'MID150BEES', 'HDFCSML250']

final['Securities']=comps

final['XIRR']=xirr_vals

# Construct lists for Volatility
vol_3m_list = [portfolio_summary.loc[portfolio_summary['Period'] == '3 Months', 'Portfolio_Volatility_%'].iloc[0]] + wv['3_months']
vol_6m_list = [portfolio_summary.loc[portfolio_summary['Period'] == '6 Months', 'Portfolio_Volatility_%'].iloc[0]] + wv['6_months']
vol_1y_list = [portfolio_summary.loc[portfolio_summary['Period'] == '1 Year', 'Portfolio_Volatility_%'].iloc[0]] + wv['1_year']

# Construct lists for Max Drawdown
dd_3m_list = [portfolio_summary.loc[portfolio_summary['Period'] == '3 Months', 'Portfolio_Max_Drawdown_%'].iloc[0]] + wdd['3_months']
dd_6m_list = [portfolio_summary.loc[portfolio_summary['Period'] == '6 Months', 'Portfolio_Max_Drawdown_%'].iloc[0]] + wdd['6_months']
dd_1y_list = [portfolio_summary.loc[portfolio_summary['Period'] == '1 Year', 'Portfolio_Max_Drawdown_%'].iloc[0]] + wdd['1_year']

final['Vol_3m']=vol_3m_list
final['Vol_6m']=vol_6m_list
final['Vol_1y']=vol_1y_list
final['MaxDrawdown_3m']=dd_3m_list
final['MaxDrawdown_6m']=dd_6m_list
final['MaxDrawdown_1y']=dd_1y_list

final

